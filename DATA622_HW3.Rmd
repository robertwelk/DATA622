---
title: "DATA622_HW3"
author: "Robert Welk"
date: "9/24/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## tasks
1. tune hyperparameters
2. remove highly correlated predictors (lda issue)
3. EDA visuals
4. imputation
5. feature engineering
6. write-up
7. transformation?

## Packages
```{r message=F, warning=F}
library(RCurl) # for import
library(tidyverse) # cleaning/visuals
library(DataExplorer) # EDA, dummy vars
library(caret) # ML 
library(MASS) # native algorithms
library(pROC) # classification metrics
```

## Import data
-pulled from GitHub repo
```{r}
df <- read.csv("https://raw.githubusercontent.com/robertwelk/DATA622/main/Loan_approval.csv", 
               na.strings=c(""," ", "NA")) %>% 
               as_tibble()

# overview of raw data
introduce(df)
```

## Clean Data table
-Change data types 
-remove non-predictive variables
```{r}
str(df)

df$Gender <- as.factor(df$Gender)
df$Married <- as.factor(df$Married)
df$Education <- as.factor(df$Education)
df$Self_Employed <- as.factor(df$Self_Employed)
df$Credit_History <- as.factor(df$Credit_History)
df$Property_Area <- as.factor(df$Property_Area)
df$Loan_Status <- as.factor(df$Loan_Status)

### remove ID 
index <- df$Loan_ID
df <- df %>% dplyr::select(!c(Loan_ID) )
```

## EDA 
-Density
-Boxplots
-Correlation 

```{r}
plot_intro(df)
plot_missing(df)
plot_bar(df, by="Loan_Status")
plot_histogram(df)
plot_qq(df)

plot_correlation(na.omit(df), type="c")
plot_correlation(na.omit(df), type="d")
plot_boxplot(df, by="Loan_Status")


df %>% ggplot(aes(LoanAmount, col=Loan_Status)) + geom_density()
df %>% ggplot(aes(ApplicantIncome, col=Loan_Status)) + geom_density()
df %>% ggplot(aes(CoapplicantIncome, col=Loan_Status)) + geom_density()
df %>% ggplot(aes(Loan_Amount_Term, col=Loan_Status)) + geom_density()
```

## PreProcessing

### Feature Engineering
- Create features
```{r}
# new features
df$DEPENDENTS <- factor(ifelse(df$Dependents >=1, "YES", "NO")) # based on EDA


df <- drop_columns(df, "Dependents")
```

### Impute Missing Values
- any good imputation methods??
- for now missing values have been removed
```{r}
df <- df %>% filter(complete.cases(.))
```

### Dummy Variables
-do not encode the target
```{r}
# dummy varaibles created for categorical variables using DataExplorer
sapply(df,is.factor)
df <- dummify(df, select = c("Gender", "Married","Education", "Self_Employed","Credit_History","Property_Area", "DEPENDENTS") )
```


### Center/Scale
- all features centered and scaled
```{r}
center_scale <- preProcess(df, method = c("center", "scale"))
df <-predict(center_scale, df)
```
### Remove Linear Combinations
```{r}
# correaltion matrix 
cor.mat <- df %>% dplyr::select(-Loan_Status) %>% cor

#descrCor <-  cor(df)
highCorr <- sum(abs(cor.mat[upper.tri(cor.mat)]) > .999)

#caret::findLinearCombos(testing)
```

### Transformations
are transformations needed?
```{r}

```

### Train/Test Split
-80/20 split
```{r}
set.seed(2021)
trainIndex <- createDataPartition(df$Loan_Status, p = .8) %>% unlist()
training <- df[ trainIndex,]
testing  <- df[-trainIndex,]
```

### Cross Validation Setup
```{r}
# needs index see p 312
ctrl <- trainControl(method="cv",
                     number=10)
                     #summaryFunction = twoClassSummary,
                     #classProbs = TRUE,
                     #index=?,
                     #savePredictions = T)
                     
```


## Build Models

### LDA
lda2 package
tuning parameter: dimen (for lda2 only)
method='lda2'
preprocessing: center, scale, dummify

*colinnearities should be removed*
```{r}

lda.fit <- train(Loan_Status ~ ., data=training, 
                     method="lda2",
                     metric="Accuracy",
                     #tuneLength=20,
                     #tuneGrid=ridgeGrid,
                     trControl=ctrl)

lda.predict <- predict(lda.fit, testing)
plot(lda.fit)
confusionMatrix(lda.predict, testing$Loan_Status)
```

### KNN
```{r}
knn.fit <- train(Loan_Status ~ ., data=training, 
                     method="knn",
                     metric="Accuracy",
                     #preProc=c("center","scale"),  
                     tuneGrid=data.frame(.k=c(1*(0:5)+1, # what is this tune grid?
                                           2*(1:5)+1,
                                           3*(2:9)+1)),
      trControl=ctrl)

knn.predict <- predict(knn.fit, testing)
plot(knn.fit)
confusionMatrix(knn.predict, testing$Loan_Status)

# knnFit$pred <- merge(knnFit$pred, knnFit$bestTune)
# knnRoc <- roc(response = knnFit$pred$obs,
#               predictor=knnFit$pred$successful,
#               levels= rev(levels(knnFit$pred$obs)))
# 
# plot(knnRoc, legacy.axes=T)
```

### Decision Tree
```{r}
tree.fit <- train(Loan_Status ~ ., data=training, 
                     method="rpart",
                     metric="Accuracy",
                tuneLength=50,
                     #preProc=c("center","scale"),  
                     # tuneGrid=data.frame(.k=c(4*(0:5)+1, # what is this tune grid?
                     #                       20*(1:5)+1,
                     #                       50*(2:9)+1)),
      trControl=ctrl)

tree.predict <- predict(tree.fit, testing)
plot(tree.fit)
confusionMatrix(tree.predict, testing$Loan_Status)
```

### Random Forest
package=
tuning parameters=mtry 
```{r}
rf.fit <- train(Loan_Status ~ ., data=training, 
                     method="rf",
                     metric="Accuracy",
                tuneLength=10,
                     #preProc=c("center","scale"),  
                     # tuneGrid=data.frame(.k=c(4*(0:5)+1, # what is this tune grid?
                     #                       20*(1:5)+1,
                     #                       50*(2:9)+1)),
      trControl=ctrl)

rf.predict <- predict(rf.fit, testing)
plot(rf.fit)
confusionMatrix(rf.predict, testing$Loan_Status)

```

## Compare Results
based on accuracy metrics, ROC curves
varaible importance to model
interpretability?
```{r}
results <- resamples(list(lda=lda.fit,knn=knn.fit,tree=tree.fit,rf=rf.fit))
summary(results)
dotplot(results)

varImp(lda.fit)
varImp(knn.fit)
varImp(tree.fit)
varImp(rf.fit)
```
