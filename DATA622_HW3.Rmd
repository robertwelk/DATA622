---
title: "DATA622_HW3"
author: "Robert Welk"
date: "9/24/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
change 2
```{r}
library(RCurl)
library(tidyverse)
library(DataExplorer)
library(caret)
library(MASS)
library(pROC)


df <- read.csv("https://raw.githubusercontent.com/robertwelk/DATA622/main/Loan_approval.csv", na.strings=c(""," ", "NA")) %>% as_tibble()


introduce(df)
```

Change data types 
```{r}
str(df)

df$Gender <- as.factor(df$Gender)
df$Married <- as.factor(df$Married)
df$Education <- as.factor(df$Education)
df$Self_Employed <- as.factor(df$Self_Employed)
df$Credit_History <- as.factor(df$Credit_History)
df$Property_Area <- as.factor(df$Property_Area)
df$Loan_Status <- as.factor(df$Loan_Status)

# new features
df$DEPENDENTS <- factor(ifelse(df$Dependents >=1, "YES", "NO")) # based on EDA

### maybe should remove later####
df <- df %>% dplyr::select(!c(Dependents,Loan_ID) )
```

Diagnostic Plots
Density
Boxplots
Correlation 
```{r}
plot_intro(df)
plot_missing(df)
plot_bar(df, by="Loan_Status")
plot_histogram(df)
plot_qq(df)

plot_correlation(na.omit(df), type="c")
plot_correlation(na.omit(df), type="d")
plot_boxplot(df, by="Loan_Status")


df %>% ggplot(aes(LoanAmount, col=Loan_Status)) + geom_density()
df %>% ggplot(aes(ApplicantIncome, col=Loan_Status)) + geom_density()
df %>% ggplot(aes(CoapplicantIncome, col=Loan_Status)) + geom_density()
df %>% ggplot(aes(Loan_Amount_Term, col=Loan_Status)) + geom_density()
```

PreProcessing
Handle Missing Values
Feature Engineering
  -   for example, dependents could be yes or no
One hot encoding for categoricals
train test split
transformations -> Boxcox

```{r}
df <- df %>% filter(complete.cases(.))

# Train/Test Split
set.seed(2021)
trainIndex <- createDataPartition(df$Loan_Status, p = .8) %>% unlist()
training <- df[ trainIndex,]
testing  <- df[-trainIndex,]
```

Cross Validation Setup
```{r}


ctrl <- trainControl(method="cv", 
                     number=10, 
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)
```

LDA
lda2 package
tuning parameter: dimen
method='lda2'
preprocessing: center, scale, dummify

```{r}

train(Loan_Status ~ ., data=training, 
                     method="lda2",
                     tuneLength=20,
                     #tuneGrid=ridgeGrid,
                     trControl=ctrl)

#lda(training[,-12], grouping=training[,12])
```

KNN
```{r}
knnFit <- train(Loan_Status ~ ., data=training, 
                     method="knn",
                     metric="ROC",
                     #preProc=c("center","scale"),  
                     tuneGrid=data.frame(.k=c(4*(0:5)+1, # what is this tune grid?
                                           20*(1:5)+1,
                                           50*(2:9)+1)),
      trControl=ctrl)

knnFit$pred <- merge(knnFit$pred, knnFit$bestTune)
knnRoc <- roc(response = knnFit$pred$obs,
              predictor=knnFit$pred$successful,
              levels= rev(levels(knnFit$pred$obs)))

plot(knnRoc, legacy.axes=T)
```

Decision Tree
```{r}

```

Random Forest
package=
tuning parameters=mtry 
```{r}
# tune a random forest model 
set.seed(1984)
model1 <- train(y~., data=simulated,
      method="rf",
      tuneLength = 10,
      trControl = trainControl(method="cv"))

```

Compare Results
```{r}

```
